This code was used to generate the paper "Modeling functional cell types in spike train data". If you use it to publish any results, please cite it:

D. N. Zdeblick, E. T. Shea-Brown, D. M. Witten, and M. A. Buice, “Modeling functional cell types in spike train data,” PLOS Computational Biology, vol. 19, no. 10, p. e1011509, Oct. 2023, doi: 10.1371/journal.pcbi.1011509.



# Repo Summary


### readme.md

This file, a guide to this repo.

### data_grabber.py

A standalone file that, when executed, downloads the IVSCC data used in the paper and saves them in `n12_cells.csv` and `ivscc_data_n12.npz`. Also generates the folder `cell_types` as a byproduct.

### n12_cells.csv

Contains metadata for the IVSCC cells
	
### ivscc_data_n12.npz 
(not tracked by git, requires running `data_grabber.py` to create)

Contains Noise 1 and Noise 2 stimuli and spiking responses of neurons (634 cre+ VISp neurons).


### helpers.py

Contains miscellaneous helper functions used by `run_script.py` and `fig_maker.py`
	
### models.py

Contains code, used by `run_script.py` for simulating and fitting GLMs and clustered GLM models
	
### run_script.py

Contains two scripts for performing all the simulation and model fits in the paper. These scripts can be run in parallel by a compute cluster. Results are saved to files in the `files` folder.

	main_sim()
simulates data from clustered GLMs and fits using the simultaneous and sequential methods

	main_data()
fits the simultaneous and sequential methods to the IVSCC data
		
### job_script.slurm

a script used to execute `run_script.py` in parallel on a compute cluster running SLURM.
	
### files

contains the results of model fitting to simulated and IVSCC data

### fig_maker.py

a script that generates all the figures in the paper and saves them to `figs`. Intermediate results are saved to files in `summary_files`

### summary_files

contains intermediate results generated by `fig_maker.py`. These allow for faster execution of `fig_maker.py` if it is executed a second time.

### figs

contains all the figures in main and supplement of the paper

### cell_types

stores all the downloaded NDWB files with the IVSCC data. This whole folder is automatically generated by `data_grabber.py`, and can be safely deleted at any time



# Result Replication


To replicate our results, perform the following steps. This repo already contains the results of running these steps, with the exception that `ivscc_data_n12.npz` has been removed (its filesize is too big for Github).


### Step 1: Setup environment

yaml file!!!


### Step 2: Download data:

	python data_grabber.py

This should create two files, `n12_cells.csv` and `ivscc_data_n12.npz`. It will also create the folder `cell_types`, which you can then delete.


At this point, your environment should be in the same state as after running all steps 1-6.


(Steps 3-5 can run concurrently)
### Step 3: Fit all the models to simulated data

3a: Select hyperparameters on the "oracle" datasets (3a1=seq, 3a2=simul). Note that 3a2 is unneccessary for case B (`share='all'`)

3b: Fit models to all other datasets with true K, varying sigma (3a1=seq, 3a2=simul)

3c: Fit with varying K, a couple sigma, and eval on held out neurons (3a1=seq, 3a2=simul)


### Step 4: Fit sequential models to IVSCC data

4a: Fit GLMs and select lambda^stim,lambda^self (all neurons)

4b: Fit GMMs (all neurons (4b1), and subsets of neurons (4b2 and 4b3))


### Step 5: Fit simultaneous models to IVSCC data

5a: big subsets of neurons

5b: small subsets of neurons

5c: all subsets of neurons


### Step 6: Generate figures:

	python fig_maker.py

To re-generate the summary files (which are used to make the figures) from the models you fit in steps 3-5, set `run = True`

### Step 7: Run supplementary analysis of fitting to data simulated using IVSCC-fitted parameters

7a: Sequential

7b: Simultaneous

### Step 8: Generate figure S!!!:

	python sim_from_fit_figmaker.py

# TODO (!!!): 

	- add file, function, class headers to .py files. Comments on array sizing.
	- Fill out readme with appropriate commands for steps for 1,3-5, reference these instructions in run_script.py and job_script.slurm
	- create yaml file for step 1
	- label every plt.savefig() call with fig reference in paper

	Questions:
	- should sequential method be a separate class, like simul? If so, how could I cleanly re-use step 1?
	- should run_script be two scripts?
	- should figs, files, summary_files be subdivided according to sim/ivscc, seq/simul?



